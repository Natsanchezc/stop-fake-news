{"cells":[{"cell_type":"code","execution_count":null,"id":"ca3bad83-5c22-41fe-b09a-90c49ad51f71","metadata":{"id":"ca3bad83-5c22-41fe-b09a-90c49ad51f71"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"e466d622-4ca9-468f-ad97-d1cff74b75d7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e466d622-4ca9-468f-ad97-d1cff74b75d7","outputId":"0621f36a-7c91-4932-b5f5-1cf1ad0f27da"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" #para gpu\n","print(device)"]},{"cell_type":"code","source":["X_train = pd.read_csv('https://raw.githubusercontent.com/psochando/sanchez.github.io/main/X_train_5000_mayus.csv')['Cuerpo']\n","X_test = pd.read_csv('https://raw.githubusercontent.com/psochando/sanchez.github.io/main/X_test_5000_mayus.csv')['Cuerpo']\n","y_train = pd.read_csv('https://raw.githubusercontent.com/psochando/sanchez.github.io/main/y_train_5000.csv')['Peri√≥dico']\n","y_test = pd.read_csv('https://raw.githubusercontent.com/psochando/sanchez.github.io/main/y_test_5000.csv')['Peri√≥dico']"],"metadata":{"id":"HSApqdmvfW26"},"id":"HSApqdmvfW26","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"H-ZdlbL_2mb2","metadata":{"id":"H-ZdlbL_2mb2"},"outputs":[],"source":["# !pip install transformers[torch] --quiet\n","# !pip install accelerate -U --quiet"]},{"cell_type":"code","execution_count":null,"id":"454ee7d0-322f-4a85-9874-623394c5ee52","metadata":{"id":"454ee7d0-322f-4a85-9874-623394c5ee52","outputId":"b549ff48-5e22-4c2b-c73d-b4bf0e3c1293"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at Geotrend/distilbert-base-es-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Geotrend/distilbert-base-es-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"Geotrend/distilbert-base-es-cased\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"Geotrend/distilbert-base-es-cased\", num_labels=5).to(device)"]},{"cell_type":"code","execution_count":null,"id":"eeb2ab82-829e-4241-bedb-024f68ad7549","metadata":{"id":"eeb2ab82-829e-4241-bedb-024f68ad7549","outputId":"4e7b2963-ba8d-4dd4-f53e-6c332afa6257"},"outputs":[{"data":{"text/plain":["'2.0.1+cu117'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__"]},{"cell_type":"code","execution_count":null,"id":"89f1a0f9-ae73-4788-9838-570f44f58aed","metadata":{"id":"89f1a0f9-ae73-4788-9838-570f44f58aed"},"outputs":[],"source":["train_encodings = tokenizer(X_train, truncation=True, padding=True)\n","test_encodings = tokenizer(X_test, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"id":"Ub2zzW9ouSIE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ub2zzW9ouSIE","outputId":"bc4e3e21-cb4b-4c59-dfb7-0d0cfc7c854b"},"outputs":[{"data":{"text/plain":["transformers.tokenization_utils_base.BatchEncoding"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["type(train_encodings)"]},{"cell_type":"code","execution_count":null,"id":"eXeLM7nJuVlw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXeLM7nJuVlw","outputId":"acdf1238-318d-4624-b881-0c849d20e3c1"},"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["train_encodings.keys()"]},{"cell_type":"code","execution_count":null,"id":"af758416-b237-487d-a2af-c39672e1f5ac","metadata":{"id":"af758416-b237-487d-a2af-c39672e1f5ac"},"outputs":[],"source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        #item es un diccionario que contiene tres keys: 'input_ids', 'attention_mask' y 'labels'\n","        #cada key contiene el tensor correspodiente al indice idx\n","        #item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n","        item = {}\n","        item['input_ids'] = torch.tensor(self.encodings['input_ids'][idx]).to(device)\n","        item['attention_mask'] = torch.tensor(self.encodings['attention_mask'][idx]).to(device)\n","        item['labels'] = torch.tensor(self.labels[idx]).to(device)\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = MyDataset(train_encodings, y_train)\n","test_dataset = MyDataset(test_encodings, y_test)"]},{"cell_type":"code","execution_count":null,"id":"1df802a0-e5f1-4073-aa8d-cc6a254e2fdc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1df802a0-e5f1-4073-aa8d-cc6a254e2fdc","outputId":"37364fa5-8a96-47e8-aab3-17cb7b11bef8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2738 2241\n"]}],"source":["print(len(train_dataset),len(test_dataset))"]},{"cell_type":"code","execution_count":null,"id":"fde8119e-2a49-4138-92c9-f0fc806a36e4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fde8119e-2a49-4138-92c9-f0fc806a36e4","outputId":"5a15c00b-551e-424d-c679-02bf85483545","tags":[]},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([   11,   258, 24389, 10869, 22484,   205,  3935,    39,  3123,  3376,\n","            25,   551,   930,   638, 24718,   101,   259, 25928,  6853,   205,\n","          1775,  5918, 25422,   233,   222,  5253, 12951,   696,   238, 16451,\n","           233,   841,  3826,   315, 10722,   281, 10778,   391,   205,   210,\n","          1554,    25,   225,  4575,   101,   225,  6401,   205,  5509,   213,\n","           205,  2204,    27, 25422,   233,   222,   238,  3249,  1794,   210,\n","         21153,   205,  3935,  3088,   101,   205,   370, 14227,   227,  1778,\n","           315, 13268,  7119, 17289,   211,   210,  1503,   227,  6240,  1472,\n","          3521,    25,   225, 20478,   417,   233,  1305,  1417,   756,  9372,\n","           386,   263,  3680,  4243,  7423,  9489,   296,  1109,  2668,   205,\n","          5072,    30,    27, 25422,   233,   222,  2179, 18559,  5053,   205,\n","           370,   275,  2290, 15110, 15149,  6181,   205,  1528, 18904,  5667,\n","         25781,    25,  1625, 25939,   205,   281, 24700, 16420,   208,    25,\n","           354,  1022, 20185,   211,  7125,   220, 11785, 10357,    25,   272,\n","           551,   930,   259, 16572,   922,   638,   220, 24718,   430,  3116,\n","          1547,   205,  8510,  9018,  1710,   214,    27, 25422,   233,   222,\n","          2958, 19271,   417,    77,   281,  6854, 25136,   208,   227, 22770,\n","            25, 12622, 18880,   208,    77,   210,  2054,  9079,   205,   281,\n","         11653,    77,  2699,   205,   370, 13075,  6535,    27, 25422,   233,\n","          1845,   282,   225,  9369,    25,   222,   210,  7584,  1408,  8160,\n","          4507,   417,  6823,   282,  5095,   374,  2654,  1873,    27,  5367,\n","           290,    27,  1648,  1298,   205,  6549,    25,   225,  6684,   205,\n","          3935,  4048,  5096,   210,  9191,   205, 25343,   205,   252,  2504,\n","          7021,  1757,    27,  3495,   296,  1059,  2163,  3293,   211,  3602,\n","           320,  1625,  5322,   205,   210,  7584,    25, 10554,  7642,   322,\n","          3301,   272, 25836,   728,   272,   210,  5482,  8713,   323, 23144,\n","           205,   296,  3201, 20032,   229,   211,   225,  3197,    27,  5319,\n","         10853,   537,  3376,   555,   225,  1068,  1360, 23454,   213,   205,\n","          6680,   215,  2584, 23127,    25,   210,   924,   222,  1764, 17772,\n","           210, 21831,   205,   549, 18027,  1061,  7423,   916,  1045,   238,\n","          7406, 11877,   211,   211,  1340,  1378,    27,  2638,  2682,    25,\n","          7467,  2801,   233,   290,  4519,  3488,   315,   736,  9688,   208,\n","            27,  7072, 17558,  2433,   445,    26,  6451,   205,   210,  7584,\n","            26,   101,  5724,  2240,  7264,   217,    26,   296,  7522,  8797,\n","           211,   210,  2504, 18882, 23840,    25,  7363,  2058,    26,  9724,\n","          6930,   352,   282,  7642,    25,   220,  7749, 25939,   272, 13174,\n","           211,   225,  3851,   205,   281, 23829,   208,    91,   210,  2755,\n","            27,    70,   240,   211, 17030, 12334,   352,   220,  6091,   282,\n","         14773,   227,  4216,    39, 15172,   229,   225,  6174,  1830, 10892,\n","            27,   258, 14100,  1867,    25,   210,  7584,  2179,  8946,  4868,\n","          1215, 17754,   211,  1340,  1378,    21,  4416,    25,  3935,   101,\n","          1117,  5426,    22,    25,   252,   211,  6862,   101,  3480,   211,\n","          2291,    25,  1999,   222,  7642,  5489,  4868, 13268,   546,  4913,\n","         22419, 17778,   270,   205,  3215,    77,   210,  7966,  9263,    27,\n","          2127,   549,  1298,   205,  6549,   211,  3935,    25, 17558,  2433,\n","           445,   101,  2240,  7264,   217,   551,  5702,   695, 22560,   220,\n","          7483,   546,   222, 22892,  4920,   272,  1039,   205,   281, 13464,\n","           211,   225,  3851,   205,   370,    79, 11544,  6818,  3688,   455,\n","           101,   210, 12344,   205,  2248,  3192,   211,  1928,  6141,  1073,\n","            25,  1039,   205,   281,  6933,  8327,   205,   210,  9392,  3280,\n","            27,    46,   549, 14814, 11608,  5322,   226,    77,  2364,  7683,\n","           225,    12], device='cuda:0'),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n"," 'labels': tensor(0, device='cuda:0')}"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0]"]},{"cell_type":"code","execution_count":null,"id":"LWsZCEavlLQI","metadata":{"id":"LWsZCEavlLQI"},"outputs":[],"source":["!pip install evaluate --quiet"]},{"cell_type":"code","execution_count":null,"id":"NsODjuiA-nzV","metadata":{"id":"NsODjuiA-nzV"},"outputs":[],"source":["import evaluate\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"id":"36416985-c22a-45f3-9c71-54eff48a3757","metadata":{"id":"36416985-c22a-45f3-9c71-54eff48a3757"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    num_train_epochs=1,              # total number of training epochs\n","    per_device_train_batch_size=6,  # batch size per device during training\n","    per_device_eval_batch_size=8,   # batch size for evaluation\n","    dataloader_pin_memory=False,     # remove if possible for faster training\n","    evaluation_strategy = \"epoch\",\n","    output_dir=\"./results\"\n",")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated ü§ó Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=test_dataset,            # evaluation dataset\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"id":"4a2e65dc-3665-41d6-af9f-af35c894a939","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"4a2e65dc-3665-41d6-af9f-af35c894a939","outputId":"7829f9b5-ec7e-4670-a1e1-d5a165b4c982","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='457' max='457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [457/457 10:14, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.143642</td>\n","      <td>0.964748</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=457, training_loss=0.26148804846164697, metrics={'train_runtime': 619.4795, 'train_samples_per_second': 4.42, 'train_steps_per_second': 0.738, 'total_flos': 362695737520128.0, 'train_loss': 0.26148804846164697, 'epoch': 1.0})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"e7bd1b72-716e-4171-a608-bff36debc9f6","metadata":{"id":"e7bd1b72-716e-4171-a608-bff36debc9f6"},"outputs":[],"source":["# import torch\n","# torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"fc7ca7bf-8338-4fc9-9e15-4d5800ab33d7","metadata":{"id":"fc7ca7bf-8338-4fc9-9e15-4d5800ab33d7"},"outputs":[],"source":["# test_preds = []\n","# for i in range(len(X_test)):\n","#     val_encoding = tokenizer(X_test[i], truncation=True, padding=True, return_tensors=\"pt\").to(device)\n","#     outputs = model(**val_encoding)\n","#     logits = outputs.logits.cpu().detach().numpy()\n","#     test_preds.append(np.argmax(logits))"]},{"cell_type":"code","execution_count":null,"id":"637441fe-9113-4861-8260-45b902f10583","metadata":{"id":"637441fe-9113-4861-8260-45b902f10583"},"outputs":[],"source":["# Datos:\n","# Epochs: 1\n","# per_device_train_batch_size=6\n","# per_device_eval_batch_size=8"]},{"cell_type":"code","execution_count":null,"id":"4b2c6c6a-d4ef-45cd-9c0c-32a0dbf80aad","metadata":{"id":"4b2c6c6a-d4ef-45cd-9c0c-32a0dbf80aad","outputId":"583d71f4-45a8-46f2-fb8b-50cc5a0072da"},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy del train:\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='624' max='343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [343/343 08:03]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0.9737034331628927"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["print('accuracy del train:')\n","trainer.evaluate(train_dataset)['eval_accuracy']"]},{"cell_type":"code","execution_count":null,"id":"204b4861-90c7-49f9-b225-6a4c838205ed","metadata":{"id":"204b4861-90c7-49f9-b225-6a4c838205ed","outputId":"721fe860-93ec-4965-9622-225d61b1433b"},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy del test:\n"]},{"data":{"text/plain":["0.9647478804105311"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["print('accuracy del test:')\n","trainer.evaluate(test_dataset)['eval_accuracy']"]},{"cell_type":"code","execution_count":null,"id":"bea90edf-ea96-4e82-9550-c2700aefd5c4","metadata":{"id":"bea90edf-ea96-4e82-9550-c2700aefd5c4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}